I am a fourth year PhD student at [University of Pennsylvania](https://www.upenn.edu/) in [Wharton Department of Statistics and Data Science](https://statistics.wharton.upenn.edu/).

I am broadly interested in the intersections between statistics, optimization and theoretical computer science.

Email: jinhobok \[at\] upenn \[dot\] edu

## Research
_Learning Acceleration Algorithms for Fast Parametric Convex Optimization with Certified Robustness_ [[arXiv]](https://www.arxiv.org/abs/2507.16264)[[code]](https://github.com/rajivsambharya/learn_algo_steps_robust)\
R. Sambharya, J. Bok, N. Matni, G. Pappas

_Optimized Methods for Composite Optimization: A Reduction Perspective_ [[arXiv]](https://arxiv.org/abs/2506.23756)\
J. Bok, J. M. Altschuler\
(Preliminary conference version appeared as:\
_Accelerating Proximal Gradient Descent via Silver Stepsizes_ [[arXiv]](https://arxiv.org/abs/2412.05497)[[PMLR]](https://proceedings.mlr.press/v291/bok25a.html)\
J. Bok, J. M. Altschuler\
_COLT 2025._)

_Shifted Interpolation for Differential Privacy_ [[arXiv]](https://arxiv.org/abs/2403.00278)[[PMLR]](https://proceedings.mlr.press/v235/bok24a.html)[[code]](https://github.com/jinhobok/shifted_interpolation_dp)\
J. Bok, W. Su, J. M. Altschuler\
_ICML 2024_\
_FORC 2024 (non-archival track)._

_On the Privacy of Noisy Stochastic Gradient Descent for Convex Optimization_ [[SICOMP]](https://epubs.siam.org/doi/10.1137/23M1556538)\
(alph) J. M. Altschuler, J. Bok, K. Talwar\
_SIAM Journal on Computing, 2024._\
<span style="color: #aaaaaa;">(Preliminary conference version appeared as:</span>\
<span style="color: #aaaaaa;">_Privacy of Noisy Stochastic Gradient Descent: More Iterations without More Privacy Loss_</span>
[[arXiv]](https://arxiv.org/abs/2205.13710)[[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/18561617ca0b4ffa293166b3186e04b0-Abstract-Conference.html)\
<span style="color: #aaaaaa;">J. M. Altschuler, K. Talwar</span>\
<span style="color: #aaaaaa;">_NeurIPS 2022._)</span>
